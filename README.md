## A comprehensive interpretable machine learning framework for Mild Cognitive Impairment and Alzheimer's disease diagnosis

This is the repository containing the code of the experiments presented in this paper. 

## Open this notebook in Google Colab:

The notebook is too large to be displayed in Github. You can either download it locally or press the button to open it in Google Colab.

<a target="_blank" href="https://colab.research.google.com/github/Marily-Vlontzou/XAI-framework-for-MCI-AD-diagnosis/blob/main/XAI_ADNI.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

## Abstract: 
An interpretable machine learning (ML) framework is introduced to enhance the diagnosis of Mild Cognitive Impairment (MCI) and Alzheimer's disease (AD) by ensuring robustness of the ML models' interpretations. The dataset used comprises volumetric measurements from brain MRI and genetic data from healthy individuals and patients with MCI/AD, obtained through the Alzheimer's Disease Neuroimaging Initiative. The existing class imbalance is addressed by an ensemble learning approach, while various attribution-based and counterfactual-based interpretability methods are leveraged towards producing diverse explanations related to the pathophysiology of MCI/AD. A unification method combining SHAP with counterfactual explanations assesses the interpretability techniques' robustness. The best performing model yielded 87.5% balanced accuracy and 90.8% F1-score. The attribution-based interpretability methods highlighted significant volumetric and genetic features related to MCI/AD risk. The unification method provided useful insights regarding those features' necessity and sufficiency, further showcasing their significance in MCI/AD diagnosis.

